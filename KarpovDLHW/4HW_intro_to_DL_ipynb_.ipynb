{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fff3906-9f0a-433f-80b9-bd410c7f0ef1",
   "metadata": {
    "id": "8fff3906-9f0a-433f-80b9-bd410c7f0ef1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8fc73a1-bdd6-4a8f-ad1d-07a24f0a5365",
   "metadata": {
    "id": "e8fc73a1-bdd6-4a8f-ad1d-07a24f0a5365"
   },
   "outputs": [],
   "source": [
    "def get_normalize(features: torch.Tensor):\n",
    "    means = (features.data/255).mean(axis=(0, 1, 2))\n",
    "    stdf = (features.data/255).std(axis=(0, 1, 2))\n",
    "    # x = features.view(n.size(1), -1).mean(1)\n",
    "    # y = features.view(n.size(1), -1).std(1)\n",
    "    return means, stdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad7130c4-2a25-41f7-8338-429c8a5287aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad7130c4-2a25-41f7-8338-429c8a5287aa",
    "outputId": "63e690c1-868a-47ea-8e1b-ddaaafd6c9fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../datasets/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:12<00:00, 13.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/cifar-10-python.tar.gz to ../datasets/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = CIFAR10(root=\"../datasets/\", train=True, download=True, transform=T.ToTensor())\n",
    "test_dataset = CIFAR10(root=\"../datasets/\", train=False, download=True, transform=T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "RFqskg2pNpSI",
   "metadata": {
    "id": "RFqskg2pNpSI"
   },
   "outputs": [],
   "source": [
    "means, stds = get_normalize(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6ae1f1-4b07-4378-abe1-7e29c1769953",
   "metadata": {
    "id": "1d6ae1f1-4b07-4378-abe1-7e29c1769953"
   },
   "outputs": [],
   "source": [
    "def get_augmentations(train: bool = True) -> T.Compose:\n",
    "    if train:\n",
    "        train = T.Compose([\n",
    "            T.Resize((224, 224)),\n",
    "            T.RandAugment(num_ops = 5, magnitude= 5),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=means, std=stds)]\n",
    "        )\n",
    "        return train\n",
    "    else:\n",
    "        test = T.Compose([\n",
    "            T.Resize((224, 224)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=means, std=stds)]\n",
    "        )\n",
    "        return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5aef775-4abc-4845-aa6a-9df41afc9995",
   "metadata": {
    "id": "d5aef775-4abc-4845-aa6a-9df41afc9995"
   },
   "outputs": [],
   "source": [
    "def predict(model: nn.Module, loader: DataLoader, device: torch.device):\n",
    "  model.eval()\n",
    "  pred = []\n",
    "  with torch.no_grad():\n",
    "    for X, Y in loader:\n",
    "      inputs = X.to(device)\n",
    "      outputs = model(inputs)\n",
    "      predicted_classes = torch.argmax(outputs, 1)\n",
    "      pred.append(predicted_classes.cpu())\n",
    "  all_predictions = torch.cat(pred, dim=0)\n",
    "\n",
    "  return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C0tNMhpwONnL",
   "metadata": {
    "id": "C0tNMhpwONnL"
   },
   "outputs": [],
   "source": [
    "class FirstModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Изменили размер линейного слоя в зависимости от выходного размера\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),  # 224 x 224 x 16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 112 x 112 x 16\n",
    "\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),  # 112 x 112 x 32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 56 x 56 x 32\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),  # 56 x 56 x 64\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 28 x 28 x 64\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),  # 28 x 28 x 128\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 14 x 14 x 128\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            # Размер после сверток и пулинга: 14 * 14 * 128 = 25088\n",
    "            nn.Linear(14 * 14 * 128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)  # 10 классов для CIFAR-10\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "DbsUC8fFSECJ",
   "metadata": {
    "id": "DbsUC8fFSECJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train(model) -> float:\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for x, y in tqdm(train_loader, desc='Train'):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        _, y_pred = torch.max(output, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (y_pred == y).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return train_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "YYsz9J-VS0zU",
   "metadata": {
    "id": "YYsz9J-VS0zU"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "@torch.inference_mode()\n",
    "def evaluate(model, loader) -> tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for x, y in tqdm(loader, desc='Evaluation'):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, y_pred = torch.max(output, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (y_pred == y).sum().item()\n",
    "\n",
    "    total_loss /= len(loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "yBLLp-TVSgal",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBLLp-TVSgal",
    "outputId": "c7716979-bcc7-4cec-f786-a73dc97405fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "W5-AqmGXS_gY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W5-AqmGXS_gY",
    "outputId": "1c401de7-aa29-4493-8c33-c4396d8010b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset  = CIFAR10(root=\"../datasets/\", train=True, transform=get_augmentations())\n",
    "test_dataset = CIFAR10(root=\"../datasets/\", train=True, transform=get_augmentations(False))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8, pin_memory=True)\n",
    "valid_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QMOPnCozSPcD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMOPnCozSPcD",
    "outputId": "b2f324dc-571b-4d56-8f71-87db0e83247b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [03:21<00:00,  1.94it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:26<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 1.7623, Train Accuracy: 0.35%, Valid Loss: 1.3519, Valid Accuracy: 0.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [03:22<00:00,  1.93it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:26<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 1.3709, Train Accuracy: 0.51%, Valid Loss: 1.0727, Valid Accuracy: 0.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [03:22<00:00,  1.93it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:26<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 1.1580, Train Accuracy: 0.59%, Valid Loss: 0.8799, Valid Accuracy: 0.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [03:22<00:00,  1.94it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:26<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 1.0339, Train Accuracy: 0.64%, Valid Loss: 0.7536, Valid Accuracy: 0.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [03:22<00:00,  1.93it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:26<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.9293, Train Accuracy: 0.67%, Valid Loss: 0.6961, Valid Accuracy: 0.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [03:20<00:00,  1.95it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:25<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.8674, Train Accuracy: 0.70%, Valid Loss: 0.6048, Valid Accuracy: 0.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [03:22<00:00,  1.93it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:35<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.8072, Train Accuracy: 0.72%, Valid Loss: 0.5631, Valid Accuracy: 0.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [03:21<00:00,  1.94it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:28<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.7620, Train Accuracy: 0.73%, Valid Loss: 0.5057, Valid Accuracy: 0.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [03:22<00:00,  1.93it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:36<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.7099, Train Accuracy: 0.75%, Valid Loss: 0.4613, Valid Accuracy: 0.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [03:21<00:00,  1.94it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:26<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.6766, Train Accuracy: 0.76%, Valid Loss: 0.4320, Valid Accuracy: 0.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = FirstModel().to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epoch = 10\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "  train_loss, train_accuracy = train(model)\n",
    "  valid_loss, valid_accuracy = evaluate(model, valid_loader)\n",
    "  print(f\"Epoch [{epoch+1}/{n_epoch}], \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "          f\"Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xGWMX8JthDDd",
   "metadata": {
    "id": "xGWMX8JthDDd"
   },
   "outputs": [],
   "source": [
    "pred = predict(model, valid_loader, device)\n",
    "test = T.Compose([\n",
    "          T.Resize((224, 224)),\n",
    "          T.RandAugment(num_ops = 2, magnitude= 5),\n",
    "          T.ToTensor(),\n",
    "          T.Normalize(mean=means, std=stds)]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IrBdoJPjukzx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrBdoJPjukzx",
    "outputId": "270a9ace-bea9-4439-facd-71c8e7accb1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 9, 9,  ..., 9, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D9cGJ6FSgvF3",
   "metadata": {
    "id": "D9cGJ6FSgvF3"
   },
   "outputs": [],
   "source": [
    "test_dataset = CIFAR10(root=\"../datasets/\", train=False, transform=test)\n",
    "loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "BYnQaOzxf51e",
   "metadata": {
    "id": "BYnQaOzxf51e"
   },
   "outputs": [],
   "source": [
    "def predict_tta(model: nn.Module, loader: DataLoader, device: torch.device, iterations: int = 2):\n",
    "  model.eval()\n",
    "\n",
    "  all_logits = []  # Список для хранения логитов\n",
    "\n",
    "  with torch.no_grad():  # Отключаем градиенты для ускорения вычислений\n",
    "      for _ in range(iterations):\n",
    "          iteration_logits = []\n",
    "          for images, _ in loader:\n",
    "              images = images.to(device)  # Переносим данные на нужное устройство\n",
    "\n",
    "              # Прогоняем изображения через модель\n",
    "              logits = model(images)\n",
    "              iteration_logits.append(logits)\n",
    "\n",
    "          # Конкатенируем логиты всех батчей в этой итерации\n",
    "          all_logits.append(torch.cat(iteration_logits, dim=0))\n",
    "\n",
    "      # Преобразуем список логитов в тензор размера [N, C, iterations]\n",
    "      all_logits = torch.stack(all_logits, dim=-1)  # Размер [N, C, iterations]\n",
    "\n",
    "      # Усредняем по оси iterations (по последней оси)\n",
    "      avg_logits = all_logits.mean(dim=-1)  # Размер [N, C]\n",
    "\n",
    "      # Получаем предсказания (по индексу максимального логита)\n",
    "      preds = torch.argmax(avg_logits, dim=1)  # Индексы классов\n",
    "\n",
    "  return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7lHAuy0SrcN",
   "metadata": {
    "id": "a7lHAuy0SrcN"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J2SufNQx3uR3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2SufNQx3uR3",
    "outputId": "716b26a2-9b6a-4973-fc98-a599f5ad79dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_tta(model, loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4_3fTvvg49Bq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_3fTvvg49Bq",
    "outputId": "d360dec5-09b2-4e09-da1e-23f351072271"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 8,  ..., 5, 1, 7])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5w0hyc7U5I3E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5w0hyc7U5I3E",
    "outputId": "d99310b0-6667-4dfa-9c0c-04361978da1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3yPSJAJg3vR8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3yPSJAJg3vR8",
    "outputId": "baeda5fa-efee-419c-e565-ab57804a411d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, ..., 5, 1, 7])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model.eval()\n",
    "all_labels = []\n",
    "for inputs, labels in loader:\n",
    "  all_labels.append(labels.numpy())\n",
    "\n",
    "all_labels = np.concatenate(all_labels)\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UC5JxPJF4cVP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UC5JxPJF4cVP",
    "outputId": "52316cba-5753-44e1-ccc9-3e2fe049206b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zX-KlWys8Q8F",
   "metadata": {
    "id": "zX-KlWys8Q8F"
   },
   "outputs": [],
   "source": [
    "predictions = predictions.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JVHnAqr98Z3h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JVHnAqr98Z3h",
    "outputId": "412ceaa0-f835-4ded-cf6e-f56cd9bbf858"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, ..., 5, 1, 7])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fibkbjfp8kd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fibkbjfp8kd8",
    "outputId": "cb8f0934-0ee8-4cba-8336-97c7cb66bad6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7505"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(all_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "RJ0lEYHZ8tGz",
   "metadata": {
    "id": "RJ0lEYHZ8tGz"
   },
   "outputs": [],
   "source": [
    "class SecondPower(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Изменили размер линейного слоя в зависимости от выходного размера\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),  # 224 x 224 x 16\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 112 x 112 x 16\n",
    "\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),  # 112 x 112 x 32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 56 x 56 x 32\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),  # 56 x 56 x 64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 28 x 28 x 64\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),  # 28 x 28 x 128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 14 x 14 x 128\n",
    "\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            # Размер после сверток и пулинга: 14 * 14 * 128 = 25088\n",
    "            nn.Linear(14 * 14 * 128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            # nn.Dropout(p=0.3),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)  # 10 классов для CIFAR-10\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "YI7e6q5QRDaC",
   "metadata": {
    "id": "YI7e6q5QRDaC"
   },
   "outputs": [],
   "source": [
    "train_transforms = T.Compose(\n",
    "    [\n",
    "        T.Resize((224, 224)),\n",
    "        T.AutoAugment(T.AutoAugmentPolicy.CIFAR10),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=means, std=stds)\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = T.Compose(\n",
    "    [\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=means, std=stds)\n",
    "    ]\n",
    ")\n",
    "train_dataset  = CIFAR10(root=\"../datasets/\", train=True, transform=train_transforms)\n",
    "test_dataset = CIFAR10(root=\"../datasets/\", train=True, transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8, pin_memory=True)\n",
    "valid_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "Muhl7a68Zgit",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Muhl7a68Zgit",
    "outputId": "9700a00f-1437-4520-e425-abf19b3c2367"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [02:27<00:00,  2.65it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:31<00:00,  4.28it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/12], Train Loss: 1.5277, Train Accuracy: 0.45%, Valid Loss: 0.9926, Valid Accuracy: 0.65%\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [02:15<00:00,  2.89it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:32<00:00,  4.23it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/12], Train Loss: 1.1688, Train Accuracy: 0.59%, Valid Loss: 0.9064, Valid Accuracy: 0.68%\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [02:16<00:00,  2.86it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:29<00:00,  4.38it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/12], Train Loss: 1.0833, Train Accuracy: 0.61%, Valid Loss: 0.7947, Valid Accuracy: 0.73%\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [02:18<00:00,  2.83it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:29<00:00,  4.37it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/12], Train Loss: 0.9691, Train Accuracy: 0.66%, Valid Loss: 0.7708, Valid Accuracy: 0.77%\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [02:15<00:00,  2.88it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:32<00:00,  4.23it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/12], Train Loss: 0.9191, Train Accuracy: 0.67%, Valid Loss: 0.7023, Valid Accuracy: 0.79%\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [02:17<00:00,  2.85it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:40<00:00,  3.89it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/12], Train Loss: 0.8394, Train Accuracy: 0.70%, Valid Loss: 0.6557, Valid Accuracy: 0.84%\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [02:18<00:00,  2.81it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:41<00:00,  3.86it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/12], Train Loss: 0.7636, Train Accuracy: 0.73%, Valid Loss: 0.5502, Valid Accuracy: 0.84%\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:41<00:00,  3.87it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/12], Train Loss: 0.7117, Train Accuracy: 0.75%, Valid Loss: 0.5991, Valid Accuracy: 0.86%\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [02:14<00:00,  2.91it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:42<00:00,  3.82it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/12], Train Loss: 0.6689, Train Accuracy: 0.76%, Valid Loss: 0.4485, Valid Accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [02:17<00:00,  2.85it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:32<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/12], Train Loss: 0.5989, Train Accuracy: 0.79%, Valid Loss: 0.5007, Valid Accuracy: 0.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:30<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/12], Train Loss: 0.5510, Train Accuracy: 0.81%, Valid Loss: 0.3484, Valid Accuracy: 0.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [02:17<00:00,  2.84it/s]\n",
      "Evaluation: 100%|██████████| 391/391 [01:32<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/12], Train Loss: 0.5113, Train Accuracy: 0.82%, Valid Loss: 0.3032, Valid Accuracy: 0.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = SecondPower().to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=25)\n",
    "\n",
    "n_epoch = 12\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "  train_loss, train_accuracy = train(model)\n",
    "  valid_loss, valid_accuracy = evaluate(model, valid_loader)\n",
    "  print(f\"Epoch [{epoch+1}/{n_epoch}], \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "          f\"Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_YR5h-ANab-b",
   "metadata": {
    "id": "_YR5h-ANab-b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
